
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Practical 2: Planar data classification with one hidden layer &#8212; Deep Learning Specialization</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'C3_Practical_Test';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="4 Deep Neural Networks" href="C4.html" />
    <link rel="prev" title="3 Shallow Neural Networks" href="C3.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Deep Learning Specialization - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Deep Learning Specialization - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to Deep Learning Specialization
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="C1.html">1 Introduction to Deep Learning</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="C2.html">2 Neural Networks Basics</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="C2_Practical.html">Pre-Practical: Python Basics with Numpy (optional assignment)</a></li>
<li class="toctree-l2"><a class="reference internal" href="C2_Practical_Test.html">Practicel 1: Logistic Regression with a Neural Network mindset</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="C3.html">3 Shallow Neural Networks</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Practical 2: Planar data classification with one hidden layer</a></li>


</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="C4.html">4 Deep Neural Networks</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="C4_Practical_Test_P1.html">Practical 3: Building your Deep Neural Network: Step by Step</a></li>
<li class="toctree-l2"><a class="reference internal" href="C4_Practical_Test_P2.html">Practical 4: Deep Neural Network for Image Classification: Application</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="C5.html">5 Practical Aspects of Deep Learning</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="C5_Initialization.html">Practical 5: Initialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="C5_Regularization.html">Practical 6: Regularization</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FC3_Practical_Test.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/C3_Practical_Test.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Practical 2: Planar data classification with one hidden layer</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Practical 2: Planar data classification with one hidden layer</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#important-note-on-submission-to-the-autograder">Important Note on Submission to the AutoGrader</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#packages">1 - Packages</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#load-the-dataset">2 - Load the Dataset</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-1">Exercise 1</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-logistic-regression">3 - Simple Logistic Regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-network-model">4 - Neural Network model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-the-neural-network-structure">4.1 - Defining the neural network structure</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-2-layer-sizes">Exercise 2 - layer_sizes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#initialize-the-model-s-parameters">4.2 - Initialize the model’s parameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-3-initialize-parameters">Exercise 3 -  initialize_parameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-loop">4.3 - The Loop</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-4-forward-propagation">Exercise 4 - forward_propagation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#compute-the-cost">4.4 - Compute the Cost</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-5-compute-cost">Exercise 5 - compute_cost</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implement-backpropagation">4.5 - Implement Backpropagation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-6-backward-propagation">Exercise 6 -  backward_propagation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#update-parameters">4.6 - Update Parameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-7-update-parameters">Exercise 7 - update_parameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#integration">4.7 - Integration</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-8-nn-model">Exercise 8 - nn_model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-the-model">5 - Test the Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#predict">5.1 - Predict</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-9-predict">Exercise 9 - predict</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#test-the-model-on-the-planar-dataset">5.2 - Test the Model on the Planar Dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#congrats-on-finishing-reviewing-this-programming-assignment-material">Congrats on finishing reviewing this Programming Assignment material!</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-tuning-hidden-layer-size-optional-ungraded-exercise">6 - Exercise: Tuning hidden layer size (optional/ungraded exercise)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-performance-on-other-datasets">7 - Exercise: Performance on other datasets</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="practical-2-planar-data-classification-with-one-hidden-layer">
<h1>Practical 2: Planar data classification with one hidden layer<a class="headerlink" href="#practical-2-planar-data-classification-with-one-hidden-layer" title="Link to this heading">#</a></h1>
<p>Welcome to your week 3 programming assignment! It’s time to build your first neural network, which will have one hidden layer. Now, you’ll notice a big difference between this model and the one you implemented previously using logistic regression.</p>
<p>By the end of this assignment, you’ll be able to:</p>
<ul class="simple">
<li><p>Implement a 2-class classification neural network with a single hidden layer</p></li>
<li><p>Use units with a non-linear activation function, such as tanh</p></li>
<li><p>Compute the cross entropy loss</p></li>
<li><p>Implement forward and backward propagation</p></li>
</ul>
<section id="important-note-on-submission-to-the-autograder">
<h2>Important Note on Submission to the AutoGrader<a class="headerlink" href="#important-note-on-submission-to-the-autograder" title="Link to this heading">#</a></h2>
<p>Before submitting your assignment to the AutoGrader, please make sure you are not doing the following:</p>
<ol class="arabic simple">
<li><p>You have not added any <em>extra</em> <code class="docutils literal notranslate"><span class="pre">print</span></code> statement(s) in the assignment.</p></li>
<li><p>You have not added any <em>extra</em> code cell(s) in the assignment.</p></li>
<li><p>You have not changed any of the function parameters.</p></li>
<li><p>You are not using any global variables inside your graded exercises. Unless specifically instructed to do so, please refrain from it and use the local variables instead.</p></li>
<li><p>You are not changing the assignment code where it is not required, like creating <em>extra</em> variables.</p></li>
</ol>
<p>If you do any of the following, you will get something like, <code class="docutils literal notranslate"><span class="pre">Grader</span> <span class="pre">Error:</span> <span class="pre">Grader</span> <span class="pre">feedback</span> <span class="pre">not</span> <span class="pre">found</span></code> (or similarly unexpected) error upon submitting your assignment. Before asking for help/debugging the errors in your assignment, check for these first. If this is the case, and you don’t remember the changes you have made, you can get a fresh copy of the assignment by following these <a class="reference external" href="https://www.coursera.org/learn/neural-networks-deep-learning/supplement/iLwon/h-ow-to-refresh-your-workspace">instructions</a>.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="packages">
<h1>1 - Packages<a class="headerlink" href="#packages" title="Link to this heading">#</a></h1>
<p>First import all the packages that you will need during this assignment.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.numpy.org/">numpy</a> is the fundamental package for scientific computing with Python.</p></li>
<li><p><a class="reference external" href="http://scikit-learn.org/stable/">sklearn</a> provides simple and efficient tools for data mining and data analysis.</p></li>
<li><p><a class="reference external" href="http://matplotlib.org">matplotlib</a> is a library for plotting graphs in Python.</p></li>
<li><p>testCases provides some test examples to assess the correctness of your functions</p></li>
<li><p>planar_utils provide various useful functions used in this assignment</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Package imports</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">testCases_v2_c1w3</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">public_tests_c1w3</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">import</span> <span class="nn">sklearn.datasets</span>
<span class="kn">import</span> <span class="nn">sklearn.linear_model</span>
<span class="kn">from</span> <span class="nn">planar_utils_c1w3</span> <span class="kn">import</span> <span class="n">plot_decision_boundary</span><span class="p">,</span> <span class="n">sigmoid</span><span class="p">,</span> <span class="n">load_planar_dataset</span><span class="p">,</span> <span class="n">load_extra_datasets</span>

<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="load-the-dataset">
<h1>2 - Load the Dataset<a class="headerlink" href="#load-the-dataset" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">load_planar_dataset</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Visualize the dataset using matplotlib. The data looks like a “flower” with some red (label y=0) and some blue (y=1) points. Your goal is to build a model to fit this data. In other words, we want the classifier to define regions as either red or blue.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualize the data:</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">c</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Spectral</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7ce848841ec753d2a37852d93a82cd50688e675dd1f51ec1ff6943c563c545a5.png" src="_images/7ce848841ec753d2a37852d93a82cd50688e675dd1f51ec1ff6943c563c545a5.png" />
</div>
</div>
<p>You have:</p>
<ul class="simple">
<li><p>a numpy-array (matrix) <code class="docutils literal notranslate"><span class="pre">X</span></code> that contains your features <code class="docutils literal notranslate"><span class="pre">(x1,</span> <span class="pre">x2)</span></code></p></li>
<li><p>a numpy-array (vector) <code class="docutils literal notranslate"><span class="pre">Y</span></code> that contains your labels <code class="docutils literal notranslate"><span class="pre">(red:0,</span> <span class="pre">blue:1)</span></code>.</p></li>
</ul>
<p>First, get a better sense of what your data is like.</p>
<section id="exercise-1">
<h2>Exercise 1<a class="headerlink" href="#exercise-1" title="Link to this heading">#</a></h2>
<p>How many training examples do you have? In addition, what is the <code class="docutils literal notranslate"><span class="pre">shape</span></code> of the variables <code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">Y</span></code>?</p>
<p><strong>Hint</strong>: How do you get the shape of a numpy array? <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html">(help)</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># (≈ 3 lines of code)</span>
<span class="c1"># shape_X = ...</span>
<span class="c1"># shape_Y = ...</span>
<span class="c1"># training set size</span>
<span class="c1"># m = ...</span>
<span class="c1"># YOUR CODE STARTS HERE</span>

<span class="n">shape_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">shape_Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">X</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># YOUR CODE ENDS HERE</span>

<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;The shape of X is: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">shape_X</span><span class="p">))</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;The shape of Y is: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">shape_Y</span><span class="p">))</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;I have m = </span><span class="si">%d</span><span class="s1"> training examples!&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">m</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The shape of X is: (2, 400)
The shape of Y is: (1, 400)
I have m = 400 training examples!
</pre></div>
</div>
</div>
</div>
</section>
<section id="simple-logistic-regression">
<h2>3 - Simple Logistic Regression<a class="headerlink" href="#simple-logistic-regression" title="Link to this heading">#</a></h2>
<p>Before building a full neural network, let’s check how logistic regression performs on this problem. You can use sklearn’s built-in functions for this. Run the code below to train a logistic regression classifier on the dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train the logistic regression classifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegressionCV</span><span class="p">();</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">T</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>You can now plot the decision boundary of these models! Run the code below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot the decision boundary for logistic regression</span>
<span class="n">plot_decision_boundary</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Logistic Regression&quot;</span><span class="p">)</span>

<span class="c1"># Print accuracy</span>
<span class="n">LR_predictions</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Accuracy of logistic regression: </span><span class="si">%d</span><span class="s1"> &#39;</span> <span class="o">%</span> <span class="nb">float</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">LR_predictions</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">Y</span><span class="p">,</span><span class="mi">1</span><span class="o">-</span><span class="n">LR_predictions</span><span class="p">))</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span> <span class="o">+</span>
       <span class="s1">&#39;% &#39;</span> <span class="o">+</span> <span class="s2">&quot;(percentage of correctly labelled datapoints)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy of logistic regression: 47 % (percentage of correctly labelled datapoints)
</pre></div>
</div>
<img alt="_images/7555e38bfec3058ac37800d3ab99da0428dc13156fa830d98f089b719cdb9220.png" src="_images/7555e38bfec3058ac37800d3ab99da0428dc13156fa830d98f089b719cdb9220.png" />
</div>
</div>
<p><strong>Interpretation</strong>: The dataset is not linearly separable, so logistic regression doesn’t perform well. Hopefully a neural network will do better. Let’s try this now!</p>
</section>
<section id="neural-network-model">
<h2>4 - Neural Network model<a class="headerlink" href="#neural-network-model" title="Link to this heading">#</a></h2>
<p>Logistic regression didn’t work well on the flower dataset. Next, you’re going to train a Neural Network with a single hidden layer and see how that handles the same problem.</p>
<p><strong>The model</strong>:</p>
<figure class="align-default" id="test-1">
<a class="reference internal image-reference" href="_images/classification_kiank.png"><img alt="_images/classification_kiank.png" src="_images/classification_kiank.png" style="width: 600px; height: 360px;" /></a>
</figure>
<p><strong>Mathematically</strong>:</p>
<p>For one example <span class="math notranslate nohighlight">\(x^{(i)}\)</span>:</p>
<div class="math notranslate nohighlight">
\[z^{[1] (i)} =  W^{[1]} x^{(i)} + b^{[1]}\tag{1}\]</div>
<div class="math notranslate nohighlight">
\[a^{[1] (i)} = \tanh(z^{[1] (i)})\tag{2}\]</div>
<div class="math notranslate nohighlight">
\[z^{[2] (i)} = W^{[2]} a^{[1] (i)} + b^{[2]}\tag{3}\]</div>
<div class="math notranslate nohighlight">
\[\hat{y}^{(i)} = a^{[2] (i)} = \sigma(z^{ [2] (i)})\tag{4}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}y^{(i)}_{\text{prediction}} = 
\begin{cases} 
1 &amp; \mbox{if } a^{[2](i)} &gt; 0.5 \\ 
0 &amp; \mbox{otherwise } 
\end{cases}\end{split}\]</div>
<p>Given the predictions on all the examples, you can also compute the cost <span class="math notranslate nohighlight">\(J\)</span> as follows:</p>
<div class="math notranslate nohighlight">
\[J = - \frac{1}{m} \sum\limits_{i = 0}^{m} \large\left(\small y^{(i)}\log\left(a^{[2] (i)}\right) + (1-y^{(i)})\log\left(1- a^{[2] (i)}\right)  \large  \right) \small \tag{6}\]</div>
<p><strong>Reminder</strong>: The general methodology to build a Neural Network is to:
1. Define the neural network structure ( # of input units,  # of hidden units, etc).
2. Initialize the model’s parameters
3. Loop:
- Implement forward propagation
- Compute loss
- Implement backward propagation to get the gradients
- Update parameters (gradient descent)</p>
<p>In practice, you’ll often build helper functions to compute steps 1-3, then merge them into one function called <code class="docutils literal notranslate"><span class="pre">nn_model()</span></code>. Once you’ve built <code class="docutils literal notranslate"><span class="pre">nn_model()</span></code> and learned the right parameters, you can make predictions on new data.</p>
<section id="defining-the-neural-network-structure">
<h3>4.1 - Defining the neural network structure<a class="headerlink" href="#defining-the-neural-network-structure" title="Link to this heading">#</a></h3>
</section>
<section id="exercise-2-layer-sizes">
<h3>Exercise 2 - layer_sizes<a class="headerlink" href="#exercise-2-layer-sizes" title="Link to this heading">#</a></h3>
<p>Define three variables:</p>
<ul class="simple">
<li><p>n_x: the size of the input layer</p></li>
<li><p>n_h: the size of the hidden layer (<strong>set this to 4, as <code class="docutils literal notranslate"><span class="pre">n_h</span> <span class="pre">=</span> <span class="pre">4</span></code>, but only for this Exercise 2</strong>)</p></li>
<li><p>n_y: the size of the output layer</p></li>
</ul>
<p><strong>Hint</strong>: Use shapes of X and Y to find n_x and n_y. Also, hard code the hidden layer size to be 4.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># GRADED FUNCTION: layer_sizes</span>

<span class="k">def</span> <span class="nf">layer_sizes</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Arguments:</span>
<span class="sd">    X -- input dataset of shape (input size, number of examples)</span>
<span class="sd">    Y -- labels of shape (output size, number of examples)</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    n_x -- the size of the input layer</span>
<span class="sd">    n_h -- the size of the hidden layer</span>
<span class="sd">    n_y -- the size of the output layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1">#(≈ 3 lines of code)</span>
    <span class="c1"># n_x = ... </span>
    <span class="c1"># n_h = ...</span>
    <span class="c1"># n_y = ... </span>
    <span class="c1"># YOUR CODE STARTS HERE</span>
    
    <span class="n">n_x</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">n_h</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">n_y</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="c1"># YOUR CODE ENDS HERE</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">n_x</span><span class="p">,</span> <span class="n">n_h</span><span class="p">,</span> <span class="n">n_y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t_X</span><span class="p">,</span> <span class="n">t_Y</span> <span class="o">=</span> <span class="n">layer_sizes_test_case</span><span class="p">()</span>
<span class="p">(</span><span class="n">n_x</span><span class="p">,</span> <span class="n">n_h</span><span class="p">,</span> <span class="n">n_y</span><span class="p">)</span> <span class="o">=</span> <span class="n">layer_sizes</span><span class="p">(</span><span class="n">t_X</span><span class="p">,</span> <span class="n">t_Y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The size of the input layer is: n_x = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_x</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The size of the hidden layer is: n_h = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_h</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The size of the output layer is: n_y = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_y</span><span class="p">))</span>

<span class="n">layer_sizes_test</span><span class="p">(</span><span class="n">layer_sizes</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The size of the input layer is: n_x = 5
The size of the hidden layer is: n_h = 4
The size of the output layer is: n_y = 2
All tests passed!
</pre></div>
</div>
</div>
</div>
</section>
<section id="initialize-the-model-s-parameters">
<h3>4.2 - Initialize the model’s parameters<a class="headerlink" href="#initialize-the-model-s-parameters" title="Link to this heading">#</a></h3>
</section>
<section id="exercise-3-initialize-parameters">
<h3>Exercise 3 -  initialize_parameters<a class="headerlink" href="#exercise-3-initialize-parameters" title="Link to this heading">#</a></h3>
<p>Implement the function <code class="docutils literal notranslate"><span class="pre">initialize_parameters()</span></code>.</p>
<p><strong>Instructions</strong>:</p>
<ul class="simple">
<li><p>Make sure your parameters’ sizes are right. Refer to the neural network figure above if needed.</p></li>
<li><p>You will initialize the weights matrices with random values.</p>
<ul>
<li><p>Use: <code class="docutils literal notranslate"><span class="pre">np.random.randn(a,b)</span> <span class="pre">*</span> <span class="pre">0.01</span></code> to randomly initialize a matrix of shape (a,b).</p></li>
</ul>
</li>
<li><p>You will initialize the bias vectors as zeros.</p>
<ul>
<li><p>Use: <code class="docutils literal notranslate"><span class="pre">np.zeros((a,b))</span></code> to initialize a matrix of shape (a,b) with zeros.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># GRADED FUNCTION: initialize_parameters</span>

<span class="k">def</span> <span class="nf">initialize_parameters</span><span class="p">(</span><span class="n">n_x</span><span class="p">,</span> <span class="n">n_h</span><span class="p">,</span> <span class="n">n_y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Argument:</span>
<span class="sd">    n_x -- size of the input layer</span>
<span class="sd">    n_h -- size of the hidden layer</span>
<span class="sd">    n_y -- size of the output layer</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    params -- python dictionary containing your parameters:</span>
<span class="sd">                    W1 -- weight matrix of shape (n_h, n_x)</span>
<span class="sd">                    b1 -- bias vector of shape (n_h, 1)</span>
<span class="sd">                    W2 -- weight matrix of shape (n_y, n_h)</span>
<span class="sd">                    b2 -- bias vector of shape (n_y, 1)</span>
<span class="sd">    &quot;&quot;&quot;</span>    
    <span class="c1">#(≈ 4 lines of code)</span>
    <span class="c1"># W1 = ...</span>
    <span class="c1"># b1 = ...</span>
    <span class="c1"># W2 = ...</span>
    <span class="c1"># b2 = ...</span>
    <span class="c1"># YOUR CODE STARTS HERE</span>
    
    <span class="n">W1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_h</span><span class="p">,</span> <span class="n">n_x</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
    <span class="n">b1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_h</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">W2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_y</span><span class="p">,</span> <span class="n">n_h</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_y</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    
    <span class="c1"># YOUR CODE ENDS HERE</span>

    <span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;W1&quot;</span><span class="p">:</span> <span class="n">W1</span><span class="p">,</span>
                  <span class="s2">&quot;b1&quot;</span><span class="p">:</span> <span class="n">b1</span><span class="p">,</span>
                  <span class="s2">&quot;W2&quot;</span><span class="p">:</span> <span class="n">W2</span><span class="p">,</span>
                  <span class="s2">&quot;b2&quot;</span><span class="p">:</span> <span class="n">b2</span><span class="p">}</span>
    
    <span class="k">return</span> <span class="n">parameters</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">n_x</span><span class="p">,</span> <span class="n">n_h</span><span class="p">,</span> <span class="n">n_y</span> <span class="o">=</span> <span class="n">initialize_parameters_test_case</span><span class="p">()</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="n">initialize_parameters</span><span class="p">(</span><span class="n">n_x</span><span class="p">,</span> <span class="n">n_h</span><span class="p">,</span> <span class="n">n_y</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;W1 = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;W1&quot;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;b1 = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;b1&quot;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;W2 = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;W2&quot;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;b2 = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;b2&quot;</span><span class="p">]))</span>

<span class="n">initialize_parameters_test</span><span class="p">(</span><span class="n">initialize_parameters</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>W1 = [[-0.00416758 -0.00056267]
 [-0.02136196  0.01640271]
 [-0.01793436 -0.00841747]
 [ 0.00502881 -0.01245288]]
b1 = [[0.]
 [0.]
 [0.]
 [0.]]
W2 = [[-0.01057952 -0.00909008  0.00551454  0.02292208]]
b2 = [[0.]]
All tests passed!
</pre></div>
</div>
</div>
</div>
</section>
<section id="the-loop">
<h3>4.3 - The Loop<a class="headerlink" href="#the-loop" title="Link to this heading">#</a></h3>
</section>
<section id="exercise-4-forward-propagation">
<h3>Exercise 4 - forward_propagation<a class="headerlink" href="#exercise-4-forward-propagation" title="Link to this heading">#</a></h3>
<p>Implement <code class="docutils literal notranslate"><span class="pre">forward_propagation()</span></code> using the following equations:</p>
<div class="math notranslate nohighlight">
\[Z^{[1]} =  W^{[1]} X + b^{[1]}\tag{7}\]</div>
<div class="math notranslate nohighlight">
\[A^{[1]} = \tanh(Z^{[1]})\tag{8}\]</div>
<div class="math notranslate nohighlight">
\[Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]}\tag{9}\]</div>
<div class="math notranslate nohighlight">
\[\hat{Y} = A^{[2]} = \sigma(Z^{[2]})\tag{10}\]</div>
<p><strong>Instructions</strong>:</p>
<ul class="simple">
<li><p>Check the mathematical representation of your classifier in the figure above.</p></li>
<li><p>Use the function <code class="docutils literal notranslate"><span class="pre">sigmoid()</span></code>. It’s built into (imported) this notebook.</p></li>
<li><p>Use the function <code class="docutils literal notranslate"><span class="pre">np.tanh()</span></code>. It’s part of the numpy library.</p></li>
<li><p>Implement using these steps:</p>
<ol class="arabic simple">
<li><p>Retrieve each parameter from the dictionary “parameters” (which is the output of <code class="docutils literal notranslate"><span class="pre">initialize_parameters()</span></code> by using <code class="docutils literal notranslate"><span class="pre">parameters[&quot;..&quot;]</span></code>.</p></li>
<li><p>Implement Forward Propagation. Compute <span class="math notranslate nohighlight">\(Z^{[1]}, A^{[1]}, Z^{[2]}\)</span> and <span class="math notranslate nohighlight">\(A^{[2]}\)</span> (the vector of all your predictions on all the examples in the training set).</p></li>
</ol>
</li>
<li><p>Values needed in the backpropagation are stored in “cache”. The cache will be given as an input to the backpropagation function.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># GRADED FUNCTION:forward_propagation</span>

<span class="k">def</span> <span class="nf">forward_propagation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">parameters</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Argument:</span>
<span class="sd">    X -- input data of size (n_x, m)</span>
<span class="sd">    parameters -- python dictionary containing your parameters (output of initialization function)</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    A2 -- The sigmoid output of the second activation</span>
<span class="sd">    cache -- a dictionary containing &quot;Z1&quot;, &quot;A1&quot;, &quot;Z2&quot; and &quot;A2&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Retrieve each parameter from the dictionary &quot;parameters&quot;</span>
    <span class="c1">#(≈ 4 lines of code)</span>
    <span class="c1"># W1 = ...</span>
    <span class="c1"># b1 = ...</span>
    <span class="c1"># W2 = ...</span>
    <span class="c1"># b2 = ...</span>
    <span class="c1"># YOUR CODE STARTS HERE</span>
    
    <span class="n">W1</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;W1&quot;</span><span class="p">]</span>
    <span class="n">b1</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;b1&quot;</span><span class="p">]</span>
    <span class="n">W2</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;W2&quot;</span><span class="p">]</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;b2&quot;</span><span class="p">]</span>
    
    <span class="c1"># YOUR CODE ENDS HERE</span>
    
    <span class="c1"># Implement Forward Propagation to calculate A2 (probabilities)</span>
    <span class="c1"># (≈ 4 lines of code)</span>
    <span class="c1"># Z1 = ...</span>
    <span class="c1"># A1 = ...</span>
    <span class="c1"># Z2 = ...</span>
    <span class="c1"># A2 = ...</span>
    <span class="c1"># YOUR CODE STARTS HERE</span>
    
    <span class="n">Z1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">b1</span>
    <span class="n">A1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">Z1</span><span class="p">)</span>
    <span class="n">Z2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W2</span><span class="p">,</span> <span class="n">A1</span><span class="p">)</span> <span class="o">+</span> <span class="n">b2</span>
    <span class="n">A2</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">Z2</span><span class="p">)</span>
    
    <span class="c1"># YOUR CODE ENDS HERE</span>
    
    <span class="k">assert</span><span class="p">(</span><span class="n">A2</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    
    <span class="n">cache</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;Z1&quot;</span><span class="p">:</span> <span class="n">Z1</span><span class="p">,</span>
             <span class="s2">&quot;A1&quot;</span><span class="p">:</span> <span class="n">A1</span><span class="p">,</span>
             <span class="s2">&quot;Z2&quot;</span><span class="p">:</span> <span class="n">Z2</span><span class="p">,</span>
             <span class="s2">&quot;A2&quot;</span><span class="p">:</span> <span class="n">A2</span><span class="p">}</span>
    
    <span class="k">return</span> <span class="n">A2</span><span class="p">,</span> <span class="n">cache</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t_X</span><span class="p">,</span> <span class="n">parameters</span> <span class="o">=</span> <span class="n">forward_propagation_test_case</span><span class="p">()</span>
<span class="n">A2</span><span class="p">,</span> <span class="n">cache</span> <span class="o">=</span> <span class="n">forward_propagation</span><span class="p">(</span><span class="n">t_X</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;A2 = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">A2</span><span class="p">))</span>

<span class="n">forward_propagation_test</span><span class="p">(</span><span class="n">forward_propagation</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>A2 = [[0.21292656 0.21274673 0.21295976]]
All tests passed!
</pre></div>
</div>
</div>
</div>
</section>
<section id="compute-the-cost">
<h3>4.4 - Compute the Cost<a class="headerlink" href="#compute-the-cost" title="Link to this heading">#</a></h3>
<p>Now that you’ve computed <span class="math notranslate nohighlight">\(A^{[2]}\)</span> (in the Python variable “<code class="docutils literal notranslate"><span class="pre">A2</span></code>”), which contains <span class="math notranslate nohighlight">\(a^{[2](i)}\)</span> for all examples, you can compute the cost function as follows:</p>
<div class="math notranslate nohighlight">
\[J = - \frac{1}{m} \sum\limits_{i = 1}^{m} \bigg( y^{(i)}\log\left(a^{[2] (i)}\right) + (1-y^{(i)})\log\left(1- a^{[2] (i)}\right) \bigg) \tag{11}\]</div>
</section>
<section id="exercise-5-compute-cost">
<h3>Exercise 5 - compute_cost<a class="headerlink" href="#exercise-5-compute-cost" title="Link to this heading">#</a></h3>
<p>Implement <code class="docutils literal notranslate"><span class="pre">compute_cost()</span></code> to compute the value of the cost <span class="math notranslate nohighlight">\(J\)</span>.</p>
<p><strong>Instructions</strong>:</p>
<ul class="simple">
<li><p>There are many ways to implement the cross-entropy loss. This is one way to implement one part of the equation without for loops:
<span class="math notranslate nohighlight">\(- \sum\limits_{i=1}^{m}  y^{(i)}\log(a^{[2](i)})\)</span>:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">logprobs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">A2</span><span class="p">),</span><span class="n">Y</span><span class="p">)</span>
<span class="n">cost</span> <span class="o">=</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">logprobs</span><span class="p">)</span>          
</pre></div>
</div>
<ul class="simple">
<li><p>Use that to build the whole expression of the cost function.</p></li>
</ul>
<p><strong>Notes</strong>:</p>
<ul class="simple">
<li><p>You can use either <code class="docutils literal notranslate"><span class="pre">np.multiply()</span></code> and then <code class="docutils literal notranslate"><span class="pre">np.sum()</span></code> or directly <code class="docutils literal notranslate"><span class="pre">np.dot()</span></code>).</p></li>
<li><p>If you use <code class="docutils literal notranslate"><span class="pre">np.multiply</span></code> followed by <code class="docutils literal notranslate"><span class="pre">np.sum</span></code> the end result will be a type <code class="docutils literal notranslate"><span class="pre">float</span></code>, whereas if you use <code class="docutils literal notranslate"><span class="pre">np.dot</span></code>, the result will be a 2D numpy array.</p></li>
<li><p>You can use <code class="docutils literal notranslate"><span class="pre">np.squeeze()</span></code> to remove redundant dimensions (in the case of single float, this will be reduced to a zero-dimension array).</p></li>
<li><p>You can also cast the array as a type <code class="docutils literal notranslate"><span class="pre">float</span></code> using <code class="docutils literal notranslate"><span class="pre">float()</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># GRADED FUNCTION: compute_cost</span>

<span class="k">def</span> <span class="nf">compute_cost</span><span class="p">(</span><span class="n">A2</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the cross-entropy cost given in equation (13)</span>
<span class="sd">    </span>
<span class="sd">    Arguments:</span>
<span class="sd">    A2 -- The sigmoid output of the second activation, of shape (1, number of examples)</span>
<span class="sd">    Y -- &quot;true&quot; labels vector of shape (1, number of examples)</span>

<span class="sd">    Returns:</span>
<span class="sd">    cost -- cross-entropy cost given equation (13)</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">m</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># number of examples</span>

    <span class="c1"># Compute the cross-entropy cost</span>
    <span class="c1"># (≈ 2 lines of code)</span>
    <span class="c1"># logprobs = ...</span>
    <span class="c1"># cost = ...</span>
    <span class="c1"># YOUR CODE STARTS HERE</span>
    
    <span class="n">logprobs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">A2</span><span class="p">),</span><span class="n">Y</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">A2</span><span class="p">),</span><span class="mi">1</span><span class="o">-</span><span class="n">Y</span><span class="p">)</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="n">m</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">logprobs</span><span class="p">)</span>
    
    <span class="c1"># YOUR CODE ENDS HERE</span>
    
    <span class="n">cost</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">cost</span><span class="p">))</span>  <span class="c1"># makes sure cost is the dimension we expect. </span>
                                    <span class="c1"># E.g., turns [[17]] into 17 </span>
    
    <span class="k">return</span> <span class="n">cost</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A2</span><span class="p">,</span> <span class="n">t_Y</span> <span class="o">=</span> <span class="n">compute_cost_test_case</span><span class="p">()</span>
<span class="n">cost</span> <span class="o">=</span> <span class="n">compute_cost</span><span class="p">(</span><span class="n">A2</span><span class="p">,</span> <span class="n">t_Y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;cost = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">compute_cost</span><span class="p">(</span><span class="n">A2</span><span class="p">,</span> <span class="n">t_Y</span><span class="p">)))</span>

<span class="n">compute_cost_test</span><span class="p">(</span><span class="n">compute_cost</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>cost = 0.6930587610394646
All tests passed!
</pre></div>
</div>
</div>
</div>
</section>
<section id="implement-backpropagation">
<h3>4.5 - Implement Backpropagation<a class="headerlink" href="#implement-backpropagation" title="Link to this heading">#</a></h3>
<p>Using the cache computed during forward propagation, you can now implement backward propagation.</p>
</section>
<section id="exercise-6-backward-propagation">
<h3>Exercise 6 -  backward_propagation<a class="headerlink" href="#exercise-6-backward-propagation" title="Link to this heading">#</a></h3>
<p>Implement the function <code class="docutils literal notranslate"><span class="pre">backward_propagation()</span></code>.</p>
<p><strong>Instructions</strong>:
Backpropagation is usually the hardest (most mathematical) part in deep learning. To help you, here again is the slide from the lecture on backpropagation. You’ll want to use the six equations on the right of this slide, since you are building a vectorized implementation.</p>
<figure class="align-default" id="test-2">
<a class="reference internal image-reference" href="_images/grad_summary.png"><img alt="_images/grad_summary.png" src="_images/grad_summary.png" style="width: 680px; height: 360px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 1 </span><span class="caption-text">Backpropagation. Use the six equations on the right</span><a class="headerlink" href="#test-2" title="Link to this image">#</a></p>
</figcaption>
</figure>
<!--
$\frac{\partial \mathcal{J} }{ \partial z_{2}^{(i)} } = \frac{1}{m} (a^{[2](i)} - y^{(i)})$

$\frac{\partial \mathcal{J} }{ \partial W_2 } = \frac{\partial \mathcal{J} }{ \partial z_{2}^{(i)} } a^{[1] (i) T} $

$\frac{\partial \mathcal{J} }{ \partial b_2 } = \sum_i{\frac{\partial \mathcal{J} }{ \partial z_{2}^{(i)}}}$

$\frac{\partial \mathcal{J} }{ \partial z_{1}^{(i)} } =  W_2^T \frac{\partial \mathcal{J} }{ \partial z_{2}^{(i)} } * ( 1 - a^{[1] (i) 2}) $

$\frac{\partial \mathcal{J} }{ \partial W_1 } = \frac{\partial \mathcal{J} }{ \partial z_{1}^{(i)} }  X^T $

$\frac{\partial \mathcal{J} _i }{ \partial b_1 } = \sum_i{\frac{\partial \mathcal{J} }{ \partial z_{1}^{(i)}}}$

- Note that $*$ denotes elementwise multiplication.
- The notation you will use is common in deep learning coding:
    - dW1 = $\frac{\partial \mathcal{J} }{ \partial W_1 }$
    - db1 = $\frac{\partial \mathcal{J} }{ \partial b_1 }$
    - dW2 = $\frac{\partial \mathcal{J} }{ \partial W_2 }$
    - db2 = $\frac{\partial \mathcal{J} }{ \partial b_2 }$
    
!-->
<ul class="simple">
<li><p>Tips:</p>
<ul>
<li><p>To compute dZ1 you’ll need to compute <span class="math notranslate nohighlight">\(g^{[1]'}(Z^{[1]})\)</span>. Since <span class="math notranslate nohighlight">\(g^{[1]}(.)\)</span> is the tanh activation function, if <span class="math notranslate nohighlight">\(a = g^{[1]}(z)\)</span> then <span class="math notranslate nohighlight">\(g^{[1]'}(z) = 1-a^2\)</span>. So you can compute
<span class="math notranslate nohighlight">\(g^{[1]'}(Z^{[1]})\)</span> using <code class="docutils literal notranslate"><span class="pre">(1</span> <span class="pre">-</span> <span class="pre">np.power(A1,</span> <span class="pre">2))</span></code>.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># GRADED FUNCTION: backward_propagation</span>

<span class="k">def</span> <span class="nf">backward_propagation</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">cache</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implement the backward propagation using the instructions above.</span>
<span class="sd">    </span>
<span class="sd">    Arguments:</span>
<span class="sd">    parameters -- python dictionary containing our parameters </span>
<span class="sd">    cache -- a dictionary containing &quot;Z1&quot;, &quot;A1&quot;, &quot;Z2&quot; and &quot;A2&quot;.</span>
<span class="sd">    X -- input data of shape (2, number of examples)</span>
<span class="sd">    Y -- &quot;true&quot; labels vector of shape (1, number of examples)</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    grads -- python dictionary containing your gradients with respect to different parameters</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1"># First, retrieve W1 and W2 from the dictionary &quot;parameters&quot;.</span>
    <span class="c1">#(≈ 2 lines of code)</span>
    <span class="c1"># W1 = ...</span>
    <span class="c1"># W2 = ...</span>
    <span class="c1"># YOUR CODE STARTS HERE</span>
    
    <span class="n">W1</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;W1&quot;</span><span class="p">]</span>
    <span class="n">W2</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;W2&quot;</span><span class="p">]</span>
    
    <span class="c1"># YOUR CODE ENDS HERE</span>
        
    <span class="c1"># Retrieve also A1 and A2 from dictionary &quot;cache&quot;.</span>
    <span class="c1">#(≈ 2 lines of code)</span>
    <span class="c1"># A1 = ...</span>
    <span class="c1"># A2 = ...</span>
    <span class="c1"># YOUR CODE STARTS HERE</span>
    
    <span class="n">A1</span> <span class="o">=</span> <span class="n">cache</span><span class="p">[</span><span class="s2">&quot;A1&quot;</span><span class="p">]</span>
    <span class="n">A2</span> <span class="o">=</span> <span class="n">cache</span><span class="p">[</span><span class="s2">&quot;A2&quot;</span><span class="p">]</span>
    
    <span class="c1"># YOUR CODE ENDS HERE</span>
    
    <span class="c1"># Backward propagation: calculate dW1, db1, dW2, db2. </span>
    <span class="c1">#(≈ 6 lines of code, corresponding to 6 equations on slide above)</span>
    <span class="c1"># dZ2 = ...</span>
    <span class="c1"># dW2 = ...</span>
    <span class="c1"># db2 = ...</span>
    <span class="c1"># dZ1 = ...</span>
    <span class="c1"># dW1 = ...</span>
    <span class="c1"># db1 = ...</span>
    <span class="c1"># YOUR CODE STARTS HERE</span>
    
    <span class="n">dZ2</span> <span class="o">=</span> <span class="n">A2</span><span class="o">-</span><span class="n">Y</span>
    <span class="n">dW2</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">m</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dZ2</span><span class="p">,</span> <span class="n">A1</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">db2</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">m</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dZ2</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">dZ1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W2</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dZ2</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">A1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">dW1</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">m</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dZ1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">db1</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">m</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dZ1</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
    
    <span class="c1"># YOUR CODE ENDS HERE</span>
    
    <span class="n">grads</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;dW1&quot;</span><span class="p">:</span> <span class="n">dW1</span><span class="p">,</span>
             <span class="s2">&quot;db1&quot;</span><span class="p">:</span> <span class="n">db1</span><span class="p">,</span>
             <span class="s2">&quot;dW2&quot;</span><span class="p">:</span> <span class="n">dW2</span><span class="p">,</span>
             <span class="s2">&quot;db2&quot;</span><span class="p">:</span> <span class="n">db2</span><span class="p">}</span>
    
    <span class="k">return</span> <span class="n">grads</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">parameters</span><span class="p">,</span> <span class="n">cache</span><span class="p">,</span> <span class="n">t_X</span><span class="p">,</span> <span class="n">t_Y</span> <span class="o">=</span> <span class="n">backward_propagation_test_case</span><span class="p">()</span>

<span class="n">grads</span> <span class="o">=</span> <span class="n">backward_propagation</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">cache</span><span class="p">,</span> <span class="n">t_X</span><span class="p">,</span> <span class="n">t_Y</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;dW1 = &quot;</span><span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">grads</span><span class="p">[</span><span class="s2">&quot;dW1&quot;</span><span class="p">]))</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;db1 = &quot;</span><span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">grads</span><span class="p">[</span><span class="s2">&quot;db1&quot;</span><span class="p">]))</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;dW2 = &quot;</span><span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">grads</span><span class="p">[</span><span class="s2">&quot;dW2&quot;</span><span class="p">]))</span>
<span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;db2 = &quot;</span><span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">grads</span><span class="p">[</span><span class="s2">&quot;db2&quot;</span><span class="p">]))</span>

<span class="n">backward_propagation_test</span><span class="p">(</span><span class="n">backward_propagation</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dW1 = [[ 0.00301023 -0.00747267]
 [ 0.00257968 -0.00641288]
 [-0.00156892  0.003893  ]
 [-0.00652037  0.01618243]]
db1 = [[ 0.00176201]
 [ 0.00150995]
 [-0.00091736]
 [-0.00381422]]
dW2 = [[ 0.00078841  0.01765429 -0.00084166 -0.01022527]]
db2 = [[-0.16655712]]
All tests passed!
</pre></div>
</div>
</div>
</div>
</section>
<section id="update-parameters">
<h3>4.6 - Update Parameters<a class="headerlink" href="#update-parameters" title="Link to this heading">#</a></h3>
</section>
<section id="exercise-7-update-parameters">
<h3>Exercise 7 - update_parameters<a class="headerlink" href="#exercise-7-update-parameters" title="Link to this heading">#</a></h3>
<p>Implement the update rule. Use gradient descent. You have to use (dW1, db1, dW2, db2) in order to update (W1, b1, W2, b2).</p>
<p><strong>General gradient descent rule</strong>: <span class="math notranslate nohighlight">\(\theta = \theta - \alpha \frac{\partial J }{ \partial \theta }\)</span> where <span class="math notranslate nohighlight">\(\alpha\)</span> is the learning rate and <span class="math notranslate nohighlight">\(\theta\)</span> represents a parameter.</p>
<figure class="align-default" id="test-3">
<a class="reference internal image-reference" href="_images/sgd.gif"><img alt="_images/sgd.gif" src="_images/sgd.gif" style="width: 360px; height: 360px;" /></a>
</figure>
<figure class="align-default" id="test-4">
<a class="reference internal image-reference" href="_images/sgd_bad.gif"><img alt="_images/sgd_bad.gif" src="_images/sgd_bad.gif" style="width: 360px; height: 360px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 2 </span><span class="caption-text">The gradient descent algorithm with a good learning rate (converging) and a bad learning rate (diverging). Images courtesy of Adam Harley.</span><a class="headerlink" href="#test-4" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p><strong>Hint</strong></p>
<ul class="simple">
<li><p>Use <code class="docutils literal notranslate"><span class="pre">copy.deepcopy(...)</span></code> when copying lists or dictionaries that are passed as parameters to functions. It avoids input parameters being modified within the function. In some scenarios, this could be inefficient, but it is required for grading purposes.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># GRADED FUNCTION: update_parameters</span>

<span class="k">def</span> <span class="nf">update_parameters</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1.2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Updates parameters using the gradient descent update rule given above</span>
<span class="sd">    </span>
<span class="sd">    Arguments:</span>
<span class="sd">    parameters -- python dictionary containing your parameters </span>
<span class="sd">    grads -- python dictionary containing your gradients </span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    parameters -- python dictionary containing your updated parameters </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Retrieve a copy of each parameter from the dictionary &quot;parameters&quot;. Use copy.deepcopy(...) for W1 and W2</span>
    <span class="c1">#(≈ 4 lines of code)</span>
    <span class="c1"># W1 = ...</span>
    <span class="c1"># b1 = ...</span>
    <span class="c1"># W2 = ...</span>
    <span class="c1"># b2 = ...</span>
    <span class="c1"># YOUR CODE STARTS HERE</span>
    
    <span class="n">W1</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;W1&quot;</span><span class="p">])</span>
    <span class="n">b1</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;b1&quot;</span><span class="p">]</span>
    <span class="n">W2</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;W2&quot;</span><span class="p">])</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;b2&quot;</span><span class="p">]</span>

    
    <span class="c1"># YOUR CODE ENDS HERE</span>
    
    <span class="c1"># Retrieve each gradient from the dictionary &quot;grads&quot;</span>
    <span class="c1">#(≈ 4 lines of code)</span>
    <span class="c1"># dW1 = ...</span>
    <span class="c1"># db1 = ...</span>
    <span class="c1"># dW2 = ...</span>
    <span class="c1"># db2 = ...</span>
    <span class="c1"># YOUR CODE STARTS HERE</span>
    
    <span class="n">dW1</span> <span class="o">=</span> <span class="n">grads</span><span class="p">[</span><span class="s2">&quot;dW1&quot;</span><span class="p">]</span>
    <span class="n">db1</span> <span class="o">=</span> <span class="n">grads</span><span class="p">[</span><span class="s2">&quot;db1&quot;</span><span class="p">]</span>
    <span class="n">dW2</span> <span class="o">=</span> <span class="n">grads</span><span class="p">[</span><span class="s2">&quot;dW2&quot;</span><span class="p">]</span>
    <span class="n">db2</span> <span class="o">=</span> <span class="n">grads</span><span class="p">[</span><span class="s2">&quot;db2&quot;</span><span class="p">]</span>
    
    <span class="c1"># YOUR CODE ENDS HERE</span>
    
    <span class="c1"># Update rule for each parameter</span>
    <span class="c1">#(≈ 4 lines of code)</span>
    <span class="c1"># W1 = ...</span>
    <span class="c1"># b1 = ...</span>
    <span class="c1"># W2 = ...</span>
    <span class="c1"># b2 = ...</span>
    <span class="c1"># YOUR CODE STARTS HERE</span>
    
    <span class="n">W1</span> <span class="o">=</span> <span class="n">W1</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dW1</span>
    <span class="n">b1</span> <span class="o">=</span> <span class="n">b1</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">db1</span>
    <span class="n">W2</span> <span class="o">=</span> <span class="n">W2</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dW2</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="n">b2</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">db2</span>
    
    <span class="c1"># YOUR CODE ENDS HERE</span>
    
    <span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;W1&quot;</span><span class="p">:</span> <span class="n">W1</span><span class="p">,</span>
                  <span class="s2">&quot;b1&quot;</span><span class="p">:</span> <span class="n">b1</span><span class="p">,</span>
                  <span class="s2">&quot;W2&quot;</span><span class="p">:</span> <span class="n">W2</span><span class="p">,</span>
                  <span class="s2">&quot;b2&quot;</span><span class="p">:</span> <span class="n">b2</span><span class="p">}</span>
    
    <span class="k">return</span> <span class="n">parameters</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">parameters</span><span class="p">,</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">update_parameters_test_case</span><span class="p">()</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="n">update_parameters</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">grads</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;W1 = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;W1&quot;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;b1 = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;b1&quot;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;W2 = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;W2&quot;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;b2 = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;b2&quot;</span><span class="p">]))</span>

<span class="n">update_parameters_test</span><span class="p">(</span><span class="n">update_parameters</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>W1 = [[-0.00643025  0.01936718]
 [-0.02410458  0.03978052]
 [-0.01653973 -0.02096177]
 [ 0.01046864 -0.05990141]]
b1 = [[-1.02420756e-06]
 [ 1.27373948e-05]
 [ 8.32996807e-07]
 [-3.20136836e-06]]
W2 = [[-0.01041081 -0.04463285  0.01758031  0.04747113]]
b2 = [[0.00010457]]
All tests passed!
</pre></div>
</div>
</div>
</div>
</section>
<section id="integration">
<h3>4.7 - Integration<a class="headerlink" href="#integration" title="Link to this heading">#</a></h3>
<p>Integrate your functions in <code class="docutils literal notranslate"><span class="pre">nn_model()</span></code></p>
</section>
<section id="exercise-8-nn-model">
<h3>Exercise 8 - nn_model<a class="headerlink" href="#exercise-8-nn-model" title="Link to this heading">#</a></h3>
<p>Build your neural network model in <code class="docutils literal notranslate"><span class="pre">nn_model()</span></code>.</p>
<p><strong>Instructions</strong>: The neural network model has to use the previous functions in the right order.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># GRADED FUNCTION: nn_model</span>

<span class="k">def</span> <span class="nf">nn_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">n_h</span><span class="p">,</span> <span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">,</span> <span class="n">print_cost</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Arguments:</span>
<span class="sd">    X -- dataset of shape (2, number of examples)</span>
<span class="sd">    Y -- labels of shape (1, number of examples)</span>
<span class="sd">    n_h -- size of the hidden layer</span>
<span class="sd">    num_iterations -- Number of iterations in gradient descent loop</span>
<span class="sd">    print_cost -- if True, print the cost every 1000 iterations</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    parameters -- parameters learnt by the model. They can then be used to predict.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">n_x</span> <span class="o">=</span> <span class="n">layer_sizes</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">n_y</span> <span class="o">=</span> <span class="n">layer_sizes</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)[</span><span class="mi">2</span><span class="p">]</span>
    
    <span class="c1"># Initialize parameters</span>
    <span class="c1">#(≈ 1 line of code)</span>
    <span class="c1"># parameters = ...</span>
    <span class="c1"># YOUR CODE STARTS HERE</span>
    
    <span class="n">parameters</span> <span class="o">=</span> <span class="n">initialize_parameters</span><span class="p">(</span><span class="n">n_x</span><span class="p">,</span> <span class="n">n_h</span><span class="p">,</span> <span class="n">n_y</span><span class="p">)</span>
    
    <span class="c1"># YOUR CODE ENDS HERE</span>
    
    <span class="c1"># Loop (gradient descent)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">):</span>
         
        <span class="c1">#(≈ 4 lines of code)</span>
        <span class="c1"># Forward propagation. Inputs: &quot;X, parameters&quot;. Outputs: &quot;A2, cache&quot;.</span>
        <span class="c1"># A2, cache = ...</span>
        
        <span class="c1"># Cost function. Inputs: &quot;A2, Y&quot;. Outputs: &quot;cost&quot;.</span>
        <span class="c1"># cost = ...</span>
 
        <span class="c1"># Backpropagation. Inputs: &quot;parameters, cache, X, Y&quot;. Outputs: &quot;grads&quot;.</span>
        <span class="c1"># grads = ...</span>
 
        <span class="c1"># Gradient descent parameter update. Inputs: &quot;parameters, grads&quot;. Outputs: &quot;parameters&quot;.</span>
        <span class="c1"># parameters = ...</span>
        
        <span class="c1"># YOUR CODE STARTS HERE</span>
        
        <span class="n">A2</span><span class="p">,</span> <span class="n">cache</span> <span class="o">=</span> <span class="n">forward_propagation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">compute_cost</span><span class="p">(</span><span class="n">A2</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">backward_propagation</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">cache</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
        <span class="n">parameters</span> <span class="o">=</span> <span class="n">update_parameters</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1.2</span><span class="p">)</span>
        
        <span class="c1"># YOUR CODE ENDS HERE</span>
        
        <span class="c1"># Print the cost every 1000 iterations</span>
        <span class="k">if</span> <span class="n">print_cost</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Cost after iteration </span><span class="si">%i</span><span class="s2">: </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">cost</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">parameters</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nn_model_test</span><span class="p">(</span><span class="n">nn_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost after iteration 0: 0.693086
Cost after iteration 1000: 0.000220
Cost after iteration 2000: 0.000108
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost after iteration 3000: 0.000072
Cost after iteration 4000: 0.000054
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost after iteration 5000: 0.000043
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost after iteration 6000: 0.000036
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost after iteration 7000: 0.000030
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost after iteration 8000: 0.000027
Cost after iteration 9000: 0.000024
W1 = [[ 0.71392202  1.31281102]
 [-0.76411243 -1.41967065]
 [-0.75040545 -1.38857337]
 [ 0.56495575  1.04857776]]
b1 = [[-0.0073536 ]
 [ 0.01534663]
 [ 0.01262938]
 [ 0.00218135]]
W2 = [[ 2.82545815 -3.3063945  -3.16116615  1.8549574 ]]
b2 = [[0.00393452]]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>All tests passed!
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="test-the-model">
<h2>5 - Test the Model<a class="headerlink" href="#test-the-model" title="Link to this heading">#</a></h2>
<section id="predict">
<h3>5.1 - Predict<a class="headerlink" href="#predict" title="Link to this heading">#</a></h3>
</section>
<section id="exercise-9-predict">
<h3>Exercise 9 - predict<a class="headerlink" href="#exercise-9-predict" title="Link to this heading">#</a></h3>
<p>Predict with your model by building <code class="docutils literal notranslate"><span class="pre">predict()</span></code>.
Use forward propagation to predict results.</p>
<p><strong>Reminder</strong>: predictions = <span class="math notranslate nohighlight">\(y_{prediction} = \mathbb 1 \text{{activation &gt; 0.5}} = \begin{cases}
      1 &amp; \text{if}\ activation &gt; 0.5 \\
      0 &amp; \text{otherwise}
    \end{cases}\)</span></p>
<p>As an example, if you would like to set the entries of a matrix X to 0 and 1 based on a threshold you would do: <code class="docutils literal notranslate"><span class="pre">X_new</span> <span class="pre">=</span> <span class="pre">(X</span> <span class="pre">&gt;</span> <span class="pre">threshold)</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># GRADED FUNCTION: predict</span>

<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Using the learned parameters, predicts a class for each example in X</span>
<span class="sd">    </span>
<span class="sd">    Arguments:</span>
<span class="sd">    parameters -- python dictionary containing your parameters </span>
<span class="sd">    X -- input data of size (n_x, m)</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    predictions -- vector of predictions of our model (red: 0 / blue: 1)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1"># Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold.</span>
    <span class="c1">#(≈ 2 lines of code)</span>
    <span class="c1"># A2, cache = ...</span>
    <span class="c1"># predictions = ...</span>
    <span class="c1"># YOUR CODE STARTS HERE</span>
    <span class="n">A2</span><span class="p">,</span> <span class="n">cache</span> <span class="o">=</span> <span class="n">forward_propagation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="p">(</span><span class="n">A2</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span>

    
    <span class="c1"># YOUR CODE ENDS HERE</span>
    
    <span class="k">return</span> <span class="n">predictions</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">parameters</span><span class="p">,</span> <span class="n">t_X</span> <span class="o">=</span> <span class="n">predict_test_case</span><span class="p">()</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">t_X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predictions: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">predictions</span><span class="p">))</span>

<span class="n">predict_test</span><span class="p">(</span><span class="n">predict</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predictions: [[ True False  True]]
All tests passed!
</pre></div>
</div>
</div>
</div>
</section>
<section id="test-the-model-on-the-planar-dataset">
<h3>5.2 - Test the Model on the Planar Dataset<a class="headerlink" href="#test-the-model-on-the-planar-dataset" title="Link to this heading">#</a></h3>
<p>It’s time to run the model and see how it performs on a planar dataset. Run the following code to test your model with a single hidden layer of <span class="math notranslate nohighlight">\(n_h\)</span> hidden units!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Build a model with a n_h-dimensional hidden layer</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="n">nn_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">n_h</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">,</span> <span class="n">print_cost</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Plot the decision boundary</span>
<span class="n">plot_decision_boundary</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">predict</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">),</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Decision Boundary for hidden layer size &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost after iteration 0: 0.693162
Cost after iteration 1000: 0.258625
Cost after iteration 2000: 0.239334
Cost after iteration 3000: 0.230802
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost after iteration 4000: 0.225528
Cost after iteration 5000: 0.221845
Cost after iteration 6000: 0.219094
Cost after iteration 7000: 0.220612
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost after iteration 8000: 0.219396
Cost after iteration 9000: 0.218481
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Decision Boundary for hidden layer size 4&#39;)
</pre></div>
</div>
<img alt="_images/bf147159ca8de05dbde90336298735b48db74a92ac3a8fc747aa275c67677917.png" src="_images/bf147159ca8de05dbde90336298735b48db74a92ac3a8fc747aa275c67677917.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Print accuracy</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Accuracy: </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">float</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">predictions</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">Y</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">predictions</span><span class="o">.</span><span class="n">T</span><span class="p">))</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;%&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 90%
</pre></div>
</div>
</div>
</div>
<p>Accuracy is really high compared to Logistic Regression. The model has learned the patterns of the flower’s petals! Unlike logistic regression, neural networks are able to learn even highly non-linear decision boundaries.</p>
</section>
<section id="congrats-on-finishing-reviewing-this-programming-assignment-material">
<h3>Congrats on finishing reviewing this Programming Assignment material!<a class="headerlink" href="#congrats-on-finishing-reviewing-this-programming-assignment-material" title="Link to this heading">#</a></h3>
<p>Here’s a quick recap of all you just accomplished:</p>
<ul class="simple">
<li><p>Built a complete 2-class classification neural network with a hidden layer</p></li>
<li><p>Made good use of a non-linear unit</p></li>
<li><p>Computed the cross entropy loss</p></li>
<li><p>Implemented forward and backward propagation</p></li>
<li><p>Seen the impact of varying the hidden layer size, including overfitting.</p></li>
</ul>
<p>You’ve created a neural network that can learn patterns! Excellent work. Below, there are some exercises to try out some other hidden layer sizes, and other datasets.</p>
</section>
</section>
<section id="exercise-tuning-hidden-layer-size-optional-ungraded-exercise">
<h2>6 - Exercise: Tuning hidden layer size (optional/ungraded exercise)<a class="headerlink" href="#exercise-tuning-hidden-layer-size-optional-ungraded-exercise" title="Link to this heading">#</a></h2>
<p>Run the following code(it may take 1-2 minutes). Then, observe different behaviors of the model for various hidden layer sizes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># This may take about 2 minutes to run</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
<span class="n">hidden_layer_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>

<span class="c1"># you can try with different hidden layer sizes</span>
<span class="c1"># but make sure before you submit the assignment it is set as &quot;hidden_layer_sizes = [1, 2, 3, 4, 5]&quot;</span>
<span class="c1"># hidden_layer_sizes = [1, 2, 3, 4, 5, 20, 50]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n_h</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Hidden Layer of size </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">n_h</span><span class="p">)</span>
    <span class="n">parameters</span> <span class="o">=</span> <span class="n">nn_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">n_h</span><span class="p">,</span> <span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">5000</span><span class="p">)</span>
    <span class="n">plot_decision_boundary</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">predict</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">),</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="nb">float</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">predictions</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">Y</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">predictions</span><span class="o">.</span><span class="n">T</span><span class="p">))</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">size</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
    <span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Accuracy for </span><span class="si">{}</span><span class="s2"> hidden units: </span><span class="si">{}</span><span class="s2"> %&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_h</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy for 1 hidden units: 67.5 %
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy for 2 hidden units: 67.25 %
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy for 3 hidden units: 90.75 %
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy for 4 hidden units: 90.5 %
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy for 5 hidden units: 91.25 %
</pre></div>
</div>
<img alt="_images/9fe10a0cf1df0a49cbcb4ed9bc0d9df2c1abe8058f5dfaf1376da064ffe8a253.png" src="_images/9fe10a0cf1df0a49cbcb4ed9bc0d9df2c1abe8058f5dfaf1376da064ffe8a253.png" />
</div>
</div>
<p><strong>Interpretation</strong>:</p>
<ul class="simple">
<li><p>The larger models (with more hidden units) are able to fit the training set better, until eventually the largest models overfit the data.</p></li>
<li><p>The best hidden layer size seems to be around <code class="docutils literal notranslate"><span class="pre">n_h</span> <span class="pre">=</span> <span class="pre">5</span></code>. Indeed, a value around here seems to  fits the data well without also incurring noticeable overfitting.</p></li>
<li><p>Later, you’ll become familiar with regularization, which lets you use very large models (such as <code class="docutils literal notranslate"><span class="pre">n_h</span> <span class="pre">=</span> <span class="pre">50</span></code>) without much overfitting.</p></li>
</ul>
<p><strong>Note</strong>: Remember to submit the assignment by clicking the blue “Submit Assignment” button at the upper-right.</p>
<p><strong>Some optional/ungraded questions that you can explore if you wish</strong>:</p>
<ul class="simple">
<li><p>What happens when you change the tanh activation for a sigmoid activation or a ReLU activation?</p></li>
<li><p>Play with the learning_rate. What happens?</p></li>
<li><p>What if we change the dataset? (See part 7 below!)</p></li>
</ul>
</section>
<section id="exercise-performance-on-other-datasets">
<h2>7 - Exercise: Performance on other datasets<a class="headerlink" href="#exercise-performance-on-other-datasets" title="Link to this heading">#</a></h2>
<p>You need rerun the whole notebook (minus the dataset part) for each of the following datasets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Datasets</span>
<span class="n">noisy_circles</span><span class="p">,</span> <span class="n">noisy_moons</span><span class="p">,</span> <span class="n">blobs</span><span class="p">,</span> <span class="n">gaussian_quantiles</span><span class="p">,</span> <span class="n">no_structure</span> <span class="o">=</span> <span class="n">load_extra_datasets</span><span class="p">()</span>

<span class="n">datasets</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;noisy_circles&quot;</span><span class="p">:</span> <span class="n">noisy_circles</span><span class="p">,</span>
            <span class="s2">&quot;noisy_moons&quot;</span><span class="p">:</span> <span class="n">noisy_moons</span><span class="p">,</span>
            <span class="s2">&quot;blobs&quot;</span><span class="p">:</span> <span class="n">blobs</span><span class="p">,</span>
            <span class="s2">&quot;gaussian_quantiles&quot;</span><span class="p">:</span> <span class="n">gaussian_quantiles</span><span class="p">}</span>

<span class="c1">### START CODE HERE ### (choose your dataset)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="s2">&quot;noisy_moons&quot;</span>
<span class="c1">### END CODE HERE ###</span>

<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="n">dataset</span><span class="p">]</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># make blobs binary</span>
<span class="k">if</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s2">&quot;blobs&quot;</span><span class="p">:</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span><span class="o">%</span><span class="k">2</span>

<span class="c1"># Visualize the data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">c</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Spectral</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c07627c5bf4de4ee364545ee181b5c0b801a68cc86bcc5b84a79fee5c6112da7.png" src="_images/c07627c5bf4de4ee364545ee181b5c0b801a68cc86bcc5b84a79fee5c6112da7.png" />
</div>
</div>
<p><strong>References</strong>:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://scs.ryerson.ca/~aharley/neural-networks/">http://scs.ryerson.ca/~aharley/neural-networks/</a></p></li>
<li><p><a class="reference external" href="http://cs231n.github.io/neural-networks-case-study/">http://cs231n.github.io/neural-networks-case-study/</a></p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="C3.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">3 Shallow Neural Networks</p>
      </div>
    </a>
    <a class="right-next"
       href="C4.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">4 Deep Neural Networks</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Practical 2: Planar data classification with one hidden layer</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#important-note-on-submission-to-the-autograder">Important Note on Submission to the AutoGrader</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#packages">1 - Packages</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#load-the-dataset">2 - Load the Dataset</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-1">Exercise 1</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-logistic-regression">3 - Simple Logistic Regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-network-model">4 - Neural Network model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-the-neural-network-structure">4.1 - Defining the neural network structure</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-2-layer-sizes">Exercise 2 - layer_sizes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#initialize-the-model-s-parameters">4.2 - Initialize the model’s parameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-3-initialize-parameters">Exercise 3 -  initialize_parameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-loop">4.3 - The Loop</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-4-forward-propagation">Exercise 4 - forward_propagation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#compute-the-cost">4.4 - Compute the Cost</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-5-compute-cost">Exercise 5 - compute_cost</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implement-backpropagation">4.5 - Implement Backpropagation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-6-backward-propagation">Exercise 6 -  backward_propagation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#update-parameters">4.6 - Update Parameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-7-update-parameters">Exercise 7 - update_parameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#integration">4.7 - Integration</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-8-nn-model">Exercise 8 - nn_model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-the-model">5 - Test the Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#predict">5.1 - Predict</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-9-predict">Exercise 9 - predict</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#test-the-model-on-the-planar-dataset">5.2 - Test the Model on the Planar Dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#congrats-on-finishing-reviewing-this-programming-assignment-material">Congrats on finishing reviewing this Programming Assignment material!</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-tuning-hidden-layer-size-optional-ungraded-exercise">6 - Exercise: Tuning hidden layer size (optional/ungraded exercise)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-performance-on-other-datasets">7 - Exercise: Performance on other datasets</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Chao
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>